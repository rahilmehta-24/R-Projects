merged_data <- merge(df1, df2, by = "ID")
library(dplyr)
rm(list = ls())
library(dplyr)
options(scipen = 99999)
## Reading the claim file - till 2022 sep end
df1_1 = read.csv("C:/Users/99015751/Desktop/Projects/CAN_Prediction/Dec22/claims_data.csv")
rm(list = ls())
library(dplyr)
library(dplyr)
options(scipen = 99999)
## Reading the claim file - till 2022 sep end
df1_1 = read.csv("C:/Users/99015751/Desktop/Projects/CAN_Prediction/Dec22/claims_data.csv")
library(dplyr)
dates <- as.Date(c("2020-01-01", "2020-01-02", "2020-01-03", "2020-01-04", "2020-01-05"), format = "%Y-%m-%d")
dates_encoded <- factorize(dates)
x <- c("male", "female", "others", "male", "female", "others")
x_encoded <- as.factor(x)
x_encoded <- as.factor(x, levels = c("male", "female", "others"))
levels(x_encoded)
factor(x_encoded)
V = c("North", "South", "East", "East")
drn <- factor(V)
drn
as.numeric(drn)
levels_order <- c("male", "female", "others")
gender_encoded <- as.factor(gender, levels = levels_order)
x <- c("male", "female", "others", "male", "female", "others")
levels_order <- c("male", "female", "others")
gender_encoded <- as.factor(gender, levels = levels_order)
x <- c("male", "female", "others", "male", "female", "others")
levels_order <- c("male", "female", "others")
x_encoded <- as.factor(x, levels = levels_order)
factor(x)
x_encoded <- as.factor(x)
factor(x)
y <- factor(x)
y
as.numeric(y)
x <- c("male", "female", "others", "male", "female", "others")
levels_order <- c("male", "female", "others")
x_encoded <- as.factor(x, levels = levels_order)
x_encoded <- as.factor(x, labels = levels_order, ordered = is.ordered(x))
x_encoded <- as.factor(x, labels = levels_order)
V = c("North", "South", "East", "East")
levels_order <- c("North", "South", "East", "East")
# Convert vector 'V' into a factor
drn <- factor(V, labels = levels_order)
V = c("North", "South", "East", "East")
levels_order <- c("North", "South", "East")
# Convert vector 'V' into a factor
drn <- factor(V, labels = levels_order)
drn
as.numeric(drn)
as.character(drn)
gc()
year <- "0020"
new_year <- paste(substring(year, 3), substring(year, 1, 2), sep="")
new_year
year <- "0020"
new_year <- paste(substring(year, 3, 4), substring(year, 1, 2), sep="")
new_year
year <- "0020"
new_year <- paste(substring(year, 3, 4), substring(year, 1, 2), sep="")
new_year
year <- "0020"
new_year <- paste(substring(year, 3, 3), substring(year, 1, 2), sep="")
new_year
library(rvest)
install.packages("rvest")
library(rvest)
library(randomForest)
# Function to scrape movie data from IMDb
get_movie_data <- function(url) {
html_page <- read_html(url)
# Extract the movie title
title <- html_page %>%
html_node("h1") %>%
html_text()
# Extract the movie budget
budget_string <- html_page %>%
html_nodes(".txt-block") %>%
html_text() %>%
grep("Budget", ., value = TRUE)
budget <- as.numeric(gsub("[^[:digit:]]", "", budget_string))
data.frame(title = title, budget = budget)
}
# Scrape movie data from IMDb
movie_urls <- c("https://www.imdb.com/title/tt0111161/",
"https://www.imdb.com/title/tt0068646/",
"https://www.imdb.com/title/tt0071562/")
movie_dfs <- lapply(movie_urls, get_movie_data)
# Function to scrape movie data from IMDb
get_movie_data <- function(url) {
html_page <- read_html(url)
# Extract the movie title
title <- html_page %>%
html_node("h1") %>%
html_text()
# Extract the movie budget
budget_string <- html_page %>%
html_nodes(".txt-block") %>%
html_text() %>%
grep("Budget", ., value = TRUE)
budget <- as.numeric(gsub("[^[:digit:]]", "", budget_string))
data.frame(title = title, budget = budget)
}
# Scrape movie data from IMDb
movie_urls <- c("https://www.imdb.com/title/tt0111161/",
"https://www.imdb.com/title/tt0068646/",
"https://www.imdb.com/title/tt0071562/")
movie_dfs <- lapply(movie_urls, get_movie_data)
test_df <- movies_df[-train_index, ]
install.packages("azuremlsdk")
install.packages("devtools")
library(reticulate)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(rpart)
library(reticulate)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(rpart)
library(caret)
library(randomForest)
library(huxtable)
require(FactoMineR)
setwd("D:/Projects/R/job_placement_survey")
job <- read.csv("D:/Projects/R/job_placement_survey/Job_Placement_Data.csv", sep = ',')
job$gender <- as.factor(job$gender)
job$ssc_board <- as.factor(job$ssc_board)
job$hsc_board <- as.factor(job$hsc_board)
job$hsc_subject <- as.factor(hsc_subject)
## Creating factors
str(job)
job$hsc_subject <- as.factor(hsc_subject)
job$undergrad_degree <- as.factor(undergrad_degree)
job$work_experience <- as.factor(job$work_experience)
job$specialisation <- as.factor(job$specialisation)
job$status <- as.factor(job$status)
class(job$hsc_subject)
job$hsc_subject <- as.factor(hsc_subject)
class(job$hsc_subject)
job$gender<- as.factor(job$gender)
job$ssc_board<- as.factor(job$ssc_board)
job$hsc_board<- as.factor(job$hsc_board)
job$hsc_subject<- as.factor(job$hsc_subject)
job$undergrad_degree<- as.factor(job$undergrad_degree)
job$work_experience<- as.factor(job$work_experience)
job$specialisation<- as.factor(job$specialisation)
job$status<- as.factor(job$status)
str(job)
nrow(job)
nrow(job)*080
nrow(job)*0.80
#setseed to keep the same sample and therefore compare models
set.seed(1)
job.idx = sample(215,172)
job.train<-job[job.idx,]
job.test<-job[-job.idx,]
# Define status as numeric binomial variable with 1 = placed and 0 = not placed
job.train$status<-ifelse(job.train$status=="Placed",1,0)
job.test$status<-ifelse(job.test$status=="Placed",1,0)
as.numeric(job.train$status)
as.numeric(job.test$status)
# Train the logistic model
logistic.fit <- glm(status~. , data = job.train, family = "binomial")
# Test the logistic model
logistic.test <- predict(logistic.fit, newdata = job.test, type = "response")
# Accuracy
logistic.pred <- ifelse(logistic.test > 0.5, "1", "0")
t <- table(logistic.pred, job.test$status)
logistic_accuracy = sum(diag(t)/sum(t))
logistic_accuracy
summary(job.train)
set.seed(1)
job.idx = sample(215,172)
job.train<-job[job.idx,]
job.test<-job[-job.idx,]
summary(job.train)
job.dt.1 = rpart(status~. , data = job.train)
rpart.plot(job.dt.1, extra = 101)
job.predict = predict(job.dt.1, job.test, type = 'class')
accuracy_table = table(job.test$status, job.predict)
accuracy = sum(diag(accuracy_table)/sum(accuracy_table))
accuracy
accuracy_table
control <- rpart.control(cp = 0, maxdepth = 3)
job.dt.2 <- rpart(status~. -emp_test_percentage -hsc_subject, data = job.train, method = "class", control = control)
rpart.plot(job.dt.2, extra = 101)
#accuracy decision tree improved
job.predict = predict(job.dt.2, job.test, type='class')
prediction_table_impr= table(job.test$status, job.predict)
acc_imp= sum(diag(prediction_table_impr)/sum(prediction_table_impr))
acc_imp
prediction_table_impr
#same training and test data
nrow(job)
215*0.8
set.seed(1)
job.idx = sample(215, 172)
job.train<-job[job.idx,]
job.test<- job[-job.idx,]
#build the random forest
as.numeric(job.train$status)
job.rf = randomForest(status ~ ., data=job.train, ntree = 500)
#random forest accuracy
job.rf.pred = predict(job.rf, job.test)
forest_table=table(job.test$status, job.rf.pred)
acc_forest= sum(diag(forest_table)/sum(forest_table))
acc_forest
#check the numbers of variables and the out of bag error
job.rf
oob.values<-vector(length=10)
for(i in 1:10){
job.rf2 = randomForest(status ~., data=job.train, mtry= i, ntree= 500)
oob.values[i]<-job.rf2$err.rate[nrow(job.rf2$err.rate),1]
}
oob.values
job.rf3 = randomForest(status ~., data=job.train, mtry= 2, ntree= 500)
job.rf3.pred = predict(job.rf3, job.test)
forest_table3 = table(job.test$status, job.rf3.pred)
acc_forest3= sum(diag(forest_table3)/sum(forest_table3))
acc_forest3
